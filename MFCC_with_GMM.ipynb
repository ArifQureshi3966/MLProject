{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MFCC with GMM",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMk2R8Q9qQzPm5Kw9Iz/3J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArifQureshi3966/MLProject/blob/main/MFCC_with_GMM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2JdStQsZ80G"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWXZhINAgGDx"
      },
      "source": [
        "#Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAAOk_rP696A",
        "outputId": "5672734f-9c19-42fd-dae5-fe86536ffe24"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMj0isSxGMGT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "810e387c-2d11-47bf-c50a-dce268d80165"
      },
      "source": [
        "!pip install python_speech_features"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp37-none-any.whl size=5887 sha256=a3565f11c71f04e21d26986b77a8369de5020662fe17b5d80883dbff458164a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYHorhYcGxQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "388c999e-899f-4dbd-860a-480f8ddc5919"
      },
      "source": [
        "!pip install pickle-mixin"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pickle-mixin\n",
            "  Downloading https://files.pythonhosted.org/packages/02/77/9d5eb2201bbc130e2a5cc41fc949e4ab0da74b619107eac1c511be3af7a7/pickle-mixin-1.0.2.tar.gz\n",
            "Building wheels for collected packages: pickle-mixin\n",
            "  Building wheel for pickle-mixin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle-mixin: filename=pickle_mixin-1.0.2-cp37-none-any.whl size=5999 sha256=35d055f83250abfe49c845de351ce7f85d8f01ead068957afc3d41e0ff31786f\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/05/42/71de70fa36b9cbb7657bb5793a16f8028c1cdc1bdd3b8e1ac3\n",
            "Successfully built pickle-mixin\n",
            "Installing collected packages: pickle-mixin\n",
            "Successfully installed pickle-mixin-1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh4Cw9o-H2cd"
      },
      "source": [
        "!pip install auto-sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cvq1Ui1VDxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "441c0d5c-9d3c-402b-a0ff-e56dae9c7a5c"
      },
      "source": [
        "!pip install librosa"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.24.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.3.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (53.0.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (20.9)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->librosa) (1.14.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pooch>=1.0->librosa) (2.4.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpqIQCK3fhWs"
      },
      "source": [
        "import numpy as np\r\n",
        "from sklearn import preprocessing\r\n",
        "import python_speech_features as mfcc\r\n",
        " \r\n",
        "def calculate_delta(array):\r\n",
        "    \"\"\"Calculate and returns the delta of given feature vector matrix\"\"\"\r\n",
        "\r\n",
        "    rows,cols = array.shape\r\n",
        "    deltas = np.zeros((rows,20))\r\n",
        "    N = 2\r\n",
        "    for i in range(rows):\r\n",
        "        index = []\r\n",
        "        j = 1\r\n",
        "        while j <= N:\r\n",
        "            if i-j < 0:\r\n",
        "                first = 0\r\n",
        "            else:\r\n",
        "                first = i-j\r\n",
        "            if i+j > rows -1:\r\n",
        "                second = rows -1\r\n",
        "            else:\r\n",
        "                second = i+j\r\n",
        "            index.append((second,first))\r\n",
        "            j+=1\r\n",
        "        deltas[i] = ( array[index[0][0]]-array[index[0][1]] + (2 * (array[index[1][0]]-array[index[1][1]])) ) / 10\r\n",
        "    return deltas\r\n",
        " \r\n",
        "def extract_features(audio,rate):\r\n",
        "    \"\"\"extract 20 dim mfcc features from an audio, performs CMS and combines\r\n",
        "    delta to make it 40 dim feature vector\"\"\"   \r\n",
        " \r\n",
        "    mfcc_feat = mfcc.mfcc(audio,rate, 0.025, 0.01,20,appendEnergy = True)\r\n",
        "    mfcc_feat = preprocessing.scale(mfcc_feat)\r\n",
        "    delta = calculate_delta(mfcc_feat)\r\n",
        "    combined = np.hstack((mfcc_feat,delta))\r\n",
        "    return combined"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6R_u0E6gJS_"
      },
      "source": [
        "#Training Speaker Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPrl6qkhgI9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e57388b7-43f7-4a76-9cdd-3655b414b7ae"
      },
      "source": [
        "import pickle\r\n",
        "import librosa\r\n",
        "import numpy as np\r\n",
        "from sklearn import mixture\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        " \r\n",
        "#path to training data\r\n",
        "source   = \"/content/drive/MyDrive/Selfdata/\"  \r\n",
        " \r\n",
        "#path where training speakers will be saved\r\n",
        "dest = \"/content/drive/MyDrive/gmm_models/\"\r\n",
        "train_file = \"/content/drive/MyDrive/Selfdata/training_data.txt\"\r\n",
        "file_paths = open(train_file,'r')\r\n",
        " \r\n",
        "count = 1\r\n",
        "# Extracting features for each speaker (5 files per speakers)\r\n",
        "features = np.asarray(())\r\n",
        "for path in file_paths:\r\n",
        "    path = path.strip()\r\n",
        "    print (path)\r\n",
        " \r\n",
        "    # read the audio\r\n",
        "    audio,sr = librosa.load(source + path, sr=16000)\r\n",
        " \r\n",
        "    # extract 40 dimensional MFCC & delta MFCC features\r\n",
        "    vector   = extract_features(audio,sr)\r\n",
        " \r\n",
        "    if features.size == 0:\r\n",
        "        features = vector\r\n",
        "    else:\r\n",
        "        features = np.vstack((features, vector))\r\n",
        "    # when features of 5 files of speaker are concatenated, then do model training\r\n",
        "    if count == 5:\r\n",
        "        gmm = mixture.GaussianMixture(n_components=16, covariance_type='diag',max_iter=200,n_init = 3)\r\n",
        "        gmm.fit(features)\r\n",
        " \r\n",
        "        # dumping the trained gaussian model\r\n",
        "        picklefile = path.split(\"-\")[0]+\".gmm\"\r\n",
        "        pickle.dump(gmm,open(dest + picklefile,'wb'))\r\n",
        "        print ('Modeling completed for speaker:',picklefile,\" with data point = \",features.shape)\r\n",
        "        features = np.asarray(())\r\n",
        "        count = 0\r\n",
        "    count = count + 1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ali-001/Ali (1).wav\n",
            "Ali-001/Ali (2).wav\n",
            "Ali-001/Ali (3).wav\n",
            "Ali-001/Ali (4).wav\n",
            "Ali-001/Ali (5).wav\n",
            "Modeling completed for speaker: Ali.gmm  with data point =  (4820, 40)\n",
            "Alsaba-002/Alsaba (1).wav\n",
            "Alsaba-002/Alsaba (2).wav\n",
            "Alsaba-002/Alsaba (3).wav\n",
            "Alsaba-002/Alsaba (4).wav\n",
            "Alsaba-002/Alsaba (5).wav\n",
            "Modeling completed for speaker: Alsaba.gmm  with data point =  (4354, 40)\n",
            "Amna-003/Amna (1).wav\n",
            "Amna-003/Amna (2).wav\n",
            "Amna-003/Amna (3).wav\n",
            "Amna-003/Amna (4).wav\n",
            "Amna-003/Amna (5).wav\n",
            "Modeling completed for speaker: Amna.gmm  with data point =  (4197, 40)\n",
            "Aneela-004/Aneela (1).wav\n",
            "Aneela-004/Aneela (2).wav\n",
            "Aneela-004/Aneela (3).wav\n",
            "Aneela-004/Aneela (4).wav\n",
            "Aneela-004/Aneela (5).wav\n",
            "Modeling completed for speaker: Aneela.gmm  with data point =  (4992, 40)\n",
            "Arif-005/Arif (1).wav\n",
            "Arif-005/Arif (2).wav\n",
            "Arif-005/Arif (3).wav\n",
            "Arif-005/Arif (4).wav\n",
            "Arif-005/Arif (5).wav\n",
            "Modeling completed for speaker: Arif.gmm  with data point =  (5271, 40)\n",
            "Bareera-006/bareera (1).wav\n",
            "Bareera-006/bareera (2).wav\n",
            "Bareera-006/bareera (3).wav\n",
            "Bareera-006/bareera (4).wav\n",
            "Bareera-006/bareera (5).wav\n",
            "Modeling completed for speaker: Bareera.gmm  with data point =  (5214, 40)\n",
            "Eshaal-007/esh (1).wav\n",
            "Eshaal-007/esh (2).wav\n",
            "Eshaal-007/esh (3).wav\n",
            "Eshaal-007/esh (4).wav\n",
            "Eshaal-007/esh (5).wav\n",
            "Modeling completed for speaker: Eshaal.gmm  with data point =  (5020, 40)\n",
            "Khalid-008/khalid (1).wav\n",
            "Khalid-008/khalid (2).wav\n",
            "Khalid-008/khalid (3).wav\n",
            "Khalid-008/khalid (4).wav\n",
            "Khalid-008/khalid (5).wav\n",
            "Modeling completed for speaker: Khalid.gmm  with data point =  (2938, 40)\n",
            "Mahnoor-009/noor (1).wav\n",
            "Mahnoor-009/noor (2).wav\n",
            "Mahnoor-009/noor (3).wav\n",
            "Mahnoor-009/noor (4).wav\n",
            "Mahnoor-009/noor (5).wav\n",
            "Modeling completed for speaker: Mahnoor.gmm  with data point =  (5158, 40)\n",
            "Naima-010/naim (1).wav\n",
            "Naima-010/naim (2).wav\n",
            "Naima-010/naim (3).wav\n",
            "Naima-010/naim (4).wav\n",
            "Naima-010/naim (5).wav\n",
            "Modeling completed for speaker: Naima.gmm  with data point =  (5051, 40)\n",
            "Riffat-011/Riffat (1).wav\n",
            "Riffat-011/Riffat (2).wav\n",
            "Riffat-011/Riffat (3).wav\n",
            "Riffat-011/Riffat (4).wav\n",
            "Riffat-011/Riffat (5).wav\n",
            "Modeling completed for speaker: Riffat.gmm  with data point =  (4044, 40)\n",
            "Saeed-012/Saeed (1).wav\n",
            "Saeed-012/Saeed (2).wav\n",
            "Saeed-012/Saeed (3).wav\n",
            "Saeed-012/Saeed (4).wav\n",
            "Saeed-012/Saeed (5).wav\n",
            "Modeling completed for speaker: Saeed.gmm  with data point =  (4706, 40)\n",
            "Wajahat-013/Waj (1).wav\n",
            "Wajahat-013/Waj (2).wav\n",
            "Wajahat-013/Waj (3).wav\n",
            "Wajahat-013/Waj (4).wav\n",
            "Wajahat-013/Waj (5).wav\n",
            "Modeling completed for speaker: Wajahat.gmm  with data point =  (3898, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBo932gngcO3"
      },
      "source": [
        "#Evaluating Performance on Test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxDth0qUgd3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b570504-1d69-4508-fb84-1816fc2dacf2"
      },
      "source": [
        "import os\r\n",
        "import librosa\r\n",
        "import pickle\r\n",
        "import numpy as np\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "import time\r\n",
        " \r\n",
        "#path to training data\r\n",
        "source   = \"/content/drive/MyDrive/Selfdata/\"\r\n",
        "modelpath = \"/content/drive/MyDrive/gmm_models/\"\r\n",
        "test_file = \"/content/drive/MyDrive/Selfdata/testing_data.txt\"\r\n",
        "file_paths = open(test_file,'r')\r\n",
        " \r\n",
        "gmm_files = [os.path.join(modelpath,fname) for fname in\r\n",
        "              os.listdir(modelpath) if fname.endswith('.gmm')]\r\n",
        " \r\n",
        "#Load the Gaussian gender Models\r\n",
        "models    = [pickle.load(open(fname,'rb')) for fname in gmm_files]\r\n",
        "speakers   = [fname.split(\"/\")[-1].split(\".gmm\")[0] for fname\r\n",
        "              in gmm_files]\r\n",
        "error = 0\r\n",
        "total_sample = 0.0\r\n",
        "# Read the test directory and get the list of test audio files\r\n",
        "for path in file_paths:   \r\n",
        "    total_sample += 1.0\r\n",
        "    path = path.strip()\r\n",
        "    print (path)\r\n",
        "    audio,sr = librosa.load(source + path, sr=16000)\r\n",
        "    vector   = extract_features(audio,sr)\r\n",
        " \r\n",
        "    log_likelihood = np.zeros(len(models)) \r\n",
        " \r\n",
        "    for i in range(len(models)):\r\n",
        "        gmm    = models[i]  #checking with each model one by one\r\n",
        "        scores = np.array(gmm.score(vector))\r\n",
        "        log_likelihood[i] = scores.sum()\r\n",
        " \r\n",
        "    winner = np.argmax(log_likelihood)\r\n",
        "    print (\"\\tdetected as - \", speakers[winner])\r\n",
        "\r\n",
        "    checker_name = path.split(\"-\")[0]\r\n",
        "    #checker_name = path.split(\"/\")[-1].split(\" \")[0]\r\n",
        "    if speakers[winner]!= checker_name:\r\n",
        "      error += 1\r\n",
        "    time.sleep(1.0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ali-001/Ali (6).wav\n",
            "\tdetected as -  Ali\n",
            "Ali-001/Ali (7).wav\n",
            "\tdetected as -  Ali\n",
            "Ali-001/Ali (8).wav\n",
            "\tdetected as -  Ali\n",
            "Ali-001/Ali (9).wav\n",
            "\tdetected as -  Ali\n",
            "Ali-001/Ali (10).wav\n",
            "\tdetected as -  Ali\n",
            "Alsaba-002/Alsaba (6).wav\n",
            "\tdetected as -  Alsaba\n",
            "Alsaba-002/Alsaba (7).wav\n",
            "\tdetected as -  Alsaba\n",
            "Alsaba-002/Alsaba (8).wav\n",
            "\tdetected as -  Alsaba\n",
            "Alsaba-002/Alsaba (9).wav\n",
            "\tdetected as -  Alsaba\n",
            "Alsaba-002/Alsaba (10).wav\n",
            "\tdetected as -  Alsaba\n",
            "Amna-003/Amna (6).wav\n",
            "\tdetected as -  Amna\n",
            "Amna-003/Amna (7).wav\n",
            "\tdetected as -  Amna\n",
            "Amna-003/Amna (8).wav\n",
            "\tdetected as -  Amna\n",
            "Amna-003/Amna (9).wav\n",
            "\tdetected as -  Amna\n",
            "Amna-003/Amna (10).wav\n",
            "\tdetected as -  Amna\n",
            "Aneela-004/Aneela (6).wav\n",
            "\tdetected as -  Aneela\n",
            "Aneela-004/Aneela (7).wav\n",
            "\tdetected as -  Aneela\n",
            "Aneela-004/Aneela (8).wav\n",
            "\tdetected as -  Aneela\n",
            "Aneela-004/Aneela (9).wav\n",
            "\tdetected as -  Aneela\n",
            "Aneela-004/Aneela (10).wav\n",
            "\tdetected as -  Aneela\n",
            "Arif-005/Arif (6).wav\n",
            "\tdetected as -  Arif\n",
            "Arif-005/Arif (7).wav\n",
            "\tdetected as -  Arif\n",
            "Arif-005/Arif (8).wav\n",
            "\tdetected as -  Arif\n",
            "Arif-005/Arif (9).wav\n",
            "\tdetected as -  Arif\n",
            "Arif-005/Arif (10).wav\n",
            "\tdetected as -  Arif\n",
            "Bareera-006/bareera (6).wav\n",
            "\tdetected as -  Bareera\n",
            "Bareera-006/bareera (7).wav\n",
            "\tdetected as -  Bareera\n",
            "Bareera-006/bareera (8).wav\n",
            "\tdetected as -  Bareera\n",
            "Bareera-006/bareera (9).wav\n",
            "\tdetected as -  Bareera\n",
            "Bareera-006/bareera (10).wav\n",
            "\tdetected as -  Bareera\n",
            "Eshaal-007/esh (6).wav\n",
            "\tdetected as -  Eshaal\n",
            "Eshaal-007/esh (7).wav\n",
            "\tdetected as -  Eshaal\n",
            "Eshaal-007/esh (8).wav\n",
            "\tdetected as -  Eshaal\n",
            "Eshaal-007/esh (9).wav\n",
            "\tdetected as -  Eshaal\n",
            "Eshaal-007/esh (10).wav\n",
            "\tdetected as -  Eshaal\n",
            "Khalid-008/khalid (6).wav\n",
            "\tdetected as -  Khalid\n",
            "Khalid-008/khalid (7).wav\n",
            "\tdetected as -  Khalid\n",
            "Khalid-008/khalid (8).wav\n",
            "\tdetected as -  Khalid\n",
            "Khalid-008/khalid (9).wav\n",
            "\tdetected as -  Khalid\n",
            "Khalid-008/khalid (10).wav\n",
            "\tdetected as -  Khalid\n",
            "Mahnoor-009/noor (6).wav\n",
            "\tdetected as -  Mahnoor\n",
            "Mahnoor-009/noor (7).wav\n",
            "\tdetected as -  Mahnoor\n",
            "Mahnoor-009/noor (8).wav\n",
            "\tdetected as -  Mahnoor\n",
            "Mahnoor-009/noor (9).wav\n",
            "\tdetected as -  Mahnoor\n",
            "Mahnoor-009/noor (10).wav\n",
            "\tdetected as -  Mahnoor\n",
            "Naima-010/naim (6).wav\n",
            "\tdetected as -  Naima\n",
            "Naima-010/naim (7).wav\n",
            "\tdetected as -  Naima\n",
            "Naima-010/naim (8).wav\n",
            "\tdetected as -  Naima\n",
            "Naima-010/naim (9).wav\n",
            "\tdetected as -  Naima\n",
            "Naima-010/naim (10).wav\n",
            "\tdetected as -  Naima\n",
            "Riffat-011/Riffat (6).wav\n",
            "\tdetected as -  Riffat\n",
            "Riffat-011/Riffat (7).wav\n",
            "\tdetected as -  Riffat\n",
            "Riffat-011/Riffat (8).wav\n",
            "\tdetected as -  Riffat\n",
            "Riffat-011/Riffat (9).wav\n",
            "\tdetected as -  Riffat\n",
            "Riffat-011/Riffat (10).wav\n",
            "\tdetected as -  Riffat\n",
            "Saeed-012/Saeed (6).wav\n",
            "\tdetected as -  Saeed\n",
            "Saeed-012/Saeed (7).wav\n",
            "\tdetected as -  Saeed\n",
            "Saeed-012/Saeed (8).wav\n",
            "\tdetected as -  Saeed\n",
            "Saeed-012/Saeed (9).wav\n",
            "\tdetected as -  Saeed\n",
            "Saeed-012/Saeed (10).wav\n",
            "\tdetected as -  Saeed\n",
            "Wajahat-013/Waj (6).wav\n",
            "\tdetected as -  Wajahat\n",
            "Wajahat-013/Waj (7).wav\n",
            "\tdetected as -  Wajahat\n",
            "Wajahat-013/Waj (8).wav\n",
            "\tdetected as -  Wajahat\n",
            "Wajahat-013/Waj (9).wav\n",
            "\tdetected as -  Wajahat\n",
            "Wajahat-013/Waj (10).wav\n",
            "\tdetected as -  Wajahat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzPRKoUuggqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a4b0df-00b8-498f-9f2c-b7459a083d59"
      },
      "source": [
        "print ('Error =',error,'Total Test Samples =', total_sample)\r\n",
        "accuracy = ((total_sample - error) / total_sample) * 100\r\n",
        "print(\"The Accuracy Percentage for the current testing Performance with MFCC with GMM is : \", accuracy, \"%\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error = 0 Total Test Samples = 65.0\n",
            "The Accuracy Percentage for the current testing Performance with MFCC with GMM is :  100.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}